---
layout: distill
title: "Lecture 10"
description: "Regularization and Generalization"
date: 2025-10-13

lecturers:
  - name: Ben Lengerich
    url: "https://adaptinfer.org"

authors:
  - name: Neev Agrawal
  - name: Dong Hyeon Jeon
  - name: Colby Kipp Beliveau

editors:
  - name: Yi Zhang
---

## Today's Topics:

- [1. Improving Generalization](#1-improving-generalization)
- [2. Data Augmentation](#2-data-augmentation)
- [3. Early Stopping](#3-early-stopping)
- [4. L1 and L2 Regularization](#4-l1-and-l2-regularization)
- [5. Dropout](#5-dropout)

---

## 1. Improving Generalization

Generalization refers to how well a trained model performs on unseen data.  
A model that generalizes well captures the **true underlying patterns** in the dataset instead of memorizing noise from the training set.

Achieving high training accuracy is not enough — the goal is to ensure that the model **performs well on new data**.  
Overfitting occurs when a model is too closely tailored to the training set, leading to poor test performance.

**Key strategies to improve generalization:**

- Collect more diverse data
- Use data augmentation
- Reduce model capacity (simpler models)
- Apply regularization (L1, L2, dropout)
- Use early stopping
- Employ transfer/self-supervised learning

<figure>
  <img src="{{ '/assets/img/notes/lecture-10/figure1.png' | relative_url }}" width="550">
  <figcaption>Figure 1. Strategies for improving model generalization.</figcaption>
</figure>

---

## 2. Data Augmentation

**Data augmentation** increases dataset size by generating **label-preserving transformations** — improving robustness and reducing overfitting.  
Useful when labeled data is scarce or costly (e.g., medical imaging).

**Common augmentations:**

- Random crop / resize
- Flipping, rotation, translation, zoom
- Adding noise or color jitter
- Mixup, CutMix

These simulate real-world variations and encourage **invariant feature learning**.

<d-math block>
\mathcal{D}_{\mathrm{aug}} = \{ (h(x_i), y_i) \mid (x_i, y_i)\in\mathcal{D} \}
</d-math>

<figure>
  <img src="{{ '/assets/img/notes/lecture-10/figure2.png' | relative_url }}" width="550">
  <figcaption>Figure 2. Original vs. augmented data.</figcaption>
</figure>

---

## 3. Early Stopping

Early stopping halts training when validation performance stops improving — preventing overfitting.

**Procedure**

1. Split data into training/validation/test.
2. Track validation performance.
3. Stop training when validation loss stops decreasing.

<figure>
  <img src="{{ '/assets/img/notes/lecture-10/figure3.png' | relative_url }}" width="550">
  <figcaption>Figure 3. Early stopping accuracy curve.</figcaption>
</figure>
<figure>
  <img src="{{ '/assets/img/notes/lecture-10/figure4.png' | relative_url }}" width="550">
  <figcaption>Figure 4. Early stopping loss curve.</figcaption>
</figure>

---

## 4. L1 and L2 Regularization

Regularization penalizes large weights, encouraging simpler models and preventing overfitting.

### 4.1 L1 Regularization (Lasso)

<d-math block>
\mathcal{L}_{L1}=\frac{1}{n}\sum_{i=1}^n L(y^{[i]},\hat{y}^{[i]}) + \frac{\lambda}{n}\sum_j |w_j|
</d-math>

-L1 Regularization (Lasso) adds the sum of the absolute values of all weights as a penalty term to the loss function, helping to control model complexity.

-It drives many weights to zero, producing a sparse solution and enabling automatic feature selection.

-Geometrically, the circular contours represent the cost function, while the diamond shape represents the L1 constraint boundary. The model seeks a balance between minimizing the loss and satisfying the constraint.

-Because the diamond has sharp corners that align with the coordinate axes, the optimal point often lies on an axis, causing some weights to become exactly zero.

-This regularization prevents overfitting and makes the resulting model simpler and more interpretable.

<figure>
  <img src="{{ '/assets/img/notes/lecture-10/figure5.png' | relative_url }}" width="550">
  <figcaption>Figure 5. L1 regularization promotes sparsity.</figcaption>
</figure>

### 4.2 L2 Regularization (Ridge)

<d-math block>
\mathcal{L}_{L2}=\frac{1}{n}\sum_{i=1}^n L(y^{[i]},\hat{y}^{[i]}) + \frac{\lambda}{n}\sum_j w_j^2
</d-math>

<d-math block>
w_{i,j} := w_{i,j} - \eta\!\left(\frac{\partial L}{\partial w_{i,j}} + \frac{2\lambda}{n}w_{i,j}\right)
</d-math>

-L2 Regularization (Ridge) adds the sum of squared weights as a penalty term to the loss function, discouraging large coefficients.

-Unlike L1, it does not force weights to zero, but instead smooths them toward smaller values, distributing the influence more evenly among features.

-Geometrically, the circular contour lines represent the cost function, while the gray circle represents the L2 constraint.

-The optimal point lies where the cost contour just touches the constraint circle, balancing the trade-off between minimizing the cost and the penalty term.

-Because the circle has no sharp corners, all weights are shrunk but rarely become zero, which means L2 encourages weight smoothing rather than sparsity.

<figure>
  <img src="{{ '/assets/img/notes/lecture-10/figure6.png' | relative_url }}" width="550">
  <figcaption>Figure 6. L2 regularization smooths weight distribution.</figcaption>
</figure>

---

## 5. Dropout

Dropout randomly removes a fraction of neurons during training — forcing the network to learn **redundant, distributed representations**.

**Why it works**

- Prevents co-adaptation
- Acts like model ensemble
- Improves robustness

<d-math block>
\tilde{h}_i = z_i h_i,\quad
z_i =
\begin{cases}
0 & \text{with probability } p \\
1 & \text{with probability } 1-p
\end{cases}
</d-math>

<figure>
  <img src="{{ '/assets/img/notes/lecture-10/figure7.png' | relative_url }}" width="550">
  <figcaption>Figure 7. Dropout training process.</figcaption>
</figure>

<figure>
  <img src="{{ '/assets/img/notes/lecture-10/figure8.png' | relative_url }}" width="550">
  <figcaption>Figure 8. Dropout improves validation accuracy.</figcaption>
</figure>

---

## Summary

Regularization and generalization methods — like **data augmentation, early stopping, L2, and dropout** — are essential to ensure models learn meaningful patterns, not noise.  
They enable robust generalization and stable performance on unseen data.

---

<footer>
<p>© 2025 University of Wisconsin — STAT 453 Lecture Notes</p>
</footer>
